{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd77ce5",
   "metadata": {},
   "source": [
    "# Cut Detection with Lucas-Kanade Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95840518",
   "metadata": {},
   "source": [
    "A script for detecting cuts using OpenCV's implementation of Lucas-Kanade optical flow. Comparing the optical flow of certain points between one frame and the next can tell us if there was a cut between the two frames, since we expect the optical flow between one shot and the next to be completely different (different objects, different scenery, etc.)\n",
    "\n",
    "Adapted from this OpenCV tutorial: https://docs.opencv.org/3.4/d4/dee/tutorial_optical_flow.html\n",
    "\n",
    "See https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323 for more information about the calcOpticalFlowPyrLK OpenCV implementation of Lucas-Kanade optical flow.\n",
    "\n",
    "This script assumes that there is a `frames` folder with subfolders (e.g. `amadeus_frames`) containing film clip frames (e.g. `amadeus_00001.jpg`)  in the same directory as the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c6a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e72c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rgb_img(img_path):\n",
    "    \"\"\"\n",
    "    Takes in img_path, the file path to an image.\n",
    "    Reads the image at that path, and returns the RGB image.\n",
    "    \"\"\"\n",
    "    img_raw = cv2.imread(img_path)\n",
    "    \n",
    "    # OpenCV imread reads in images in BGR color space, so must convert from BGR to RGB\n",
    "    img_rgb = cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c7f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_cuts_using_lucas_kanade_optical_flow(frames_dir_path, clip_name, err_threshold, num_votes_threshold):\n",
    "    \"\"\"\n",
    "    Detects cuts between frames, using OpenCV's implementation of Lucas Kanade optical flow.\n",
    "    \n",
    "    This function is adapted from this OpenCV tutorial: https://docs.opencv.org/3.4/d4/dee/tutorial_optical_flow.html\n",
    "    See https://docs.opencv.org/3.4/dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323 for more information about the calcOpticalFlowPyrLK OpenCV implementation of Lucas-Kanade optical flow.\n",
    "    \n",
    "    Parameters:\n",
    "    - frames_dir_path: the filepath to a folder with folders of film clip frames.\n",
    "    - clip_name: the name of the film clip we wish to perform cut detection for.\n",
    "    - err_threshold: a window should have err vector value above this err_threshold to contribute to a vote for this frame being part of a cut.\n",
    "    - num_votes_threshold: proportion of the windows that should have err vector value above err_threshold for a cut to be detected between old_frame and frame.\n",
    "\n",
    "    Returns a dictionary that stores cut detection results.\n",
    "    Keys are frame numbers, and values are whether or not there is a cut between the previous frame and this frame, or between this frame and the next (0 if no cut; 1 if there is a cut).\n",
    "    \"\"\"\n",
    "    # TODO: tweak?\n",
    "    # Parameters for ShiTomasi corner detection\n",
    "    feature_params = dict( maxCorners = 100,\n",
    "                           qualityLevel = 0.3,\n",
    "                           minDistance = 7,\n",
    "                           blockSize = 7 )\n",
    "\n",
    "    # TODO: tweak?\n",
    "    # Parameters for Lucas-Kanade optical flow\n",
    "    lk_params = dict( winSize  = (15, 15),\n",
    "                      maxLevel = 2,\n",
    "                      criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    # Take first frame and find corners in it\n",
    "    frame_num = 1\n",
    "    old_frame_path = frames_dir_path + \"/\" + clip_name + \"_frames/\" + clip_name + \"_{0:05d}\".format(frame_num) + \".jpg\"\n",
    "    old_frame = load_rgb_img(old_frame_path)\n",
    "\n",
    "    # Must convert image to gray in order to calculate Lucas-Kanade optical flow using OpenCV implementation\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Decide what points to track\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "    \n",
    "    # Dictionary that will store cut detection results using Lucas Kanade optical flow\n",
    "    # Keys are frame numbers, and values are whether or not there is a cut between the previous frame and this frame, or between this frame and the next (0 if no cut; 1 if there is a cut).\n",
    "    cut_label_dict = {}\n",
    "    \n",
    "    # For drawing optical flow onto the current frame\n",
    "    color = np.random.randint(0, 255, (100, 3))   # create some random colors\n",
    "    mask = np.zeros_like(old_frame)   # create a mask for drawing optical flow displacement between previous frames\n",
    "\n",
    "    # While there is a next frame...\n",
    "    frame_num = 2\n",
    "    frame_path = frames_dir_path + \"/\" + clip_name + \"_frames/\" + clip_name + \"_{0:05d}\".format(frame_num) + \".jpg\"\n",
    "    while os.path.exists(frame_path):\n",
    "        frame = load_rgb_img(frame_path)\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Calculate optical flow using Lucas-Kanade\n",
    "        # p1: output vector of 2D points (with single-precision floating-point coordinates) containing the calculated new positions of input features in the second image.\n",
    "        # status: output status vector; each element of the vector is set to 1 if the flow for the corresponding features has been found, otherwise, it is set to 0.\n",
    "        # err: output vector of errors; each element of the vector is set to an error for the corresponding feature; if the flow wasn't found then the error is not defined (use the status parameter to find such cases).\n",
    "        p1, status, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "        cut_detected = False # Assume no cut between old_frame and frame to begin with\n",
    "        \n",
    "        # Check if flow was detected for any features.\n",
    "        if len(p1[status==1]) == 0:\n",
    "            # No elements of status vector are set to 1, so no flow was detected for any of the features.\n",
    "            # Assume that means that there was a cut between previous frame and current frame.\n",
    "            cut_detected = True\n",
    "            cut_label_dict[frame_num - 1] = 1\n",
    "            cut_label_dict[frame_num] = 1\n",
    "        else:\n",
    "            num_votes = 0\n",
    "            for error in err:\n",
    "                # A window should have err vector value above err_threshold to contribute to a vote for a cut.\n",
    "                if error > err_threshold:\n",
    "                    num_votes += 1\n",
    "            \n",
    "            # > num_votes_threshold proportion of the windows should have err above err_threshold for a cut to be detected btwn old_frame and frame.\n",
    "            if num_votes / len(err) > num_votes_threshold:\n",
    "                cut_detected = True\n",
    "                cut_label_dict[frame_num - 1] = 1\n",
    "                cut_label_dict[frame_num] = 1\n",
    "            else:\n",
    "                cut_label_dict[frame_num] = 0\n",
    "\n",
    "        if cut_detected:\n",
    "            # print(\"Cut detected in\", clip_name, \"frame\", frame_num)\n",
    "            # Clear drawing mask of prior optical flow displacement lines for previous windows (points to track)\n",
    "            mask = np.zeros_like(old_frame)\n",
    "            \n",
    "            # If current frame marks the beginning of a new shot, update the points to track based on new shot.\n",
    "            good_new = cv2.goodFeaturesToTrack(frame_gray, mask = None, **feature_params)\n",
    "            if good_new is None:\n",
    "                 # Can't do anything with this frame, so move onto next frame.\n",
    "                frame_num += 1\n",
    "                frame_path = frames_dir_path + \"/\" + clip_name + \"_frames/\" + clip_name + \"_{0:05d}\".format(frame_num) + \".jpg\"\n",
    "                continue\n",
    "            good_old = []\n",
    "        else:\n",
    "            # Select good points based on the points for which the flow has been found in current frame\n",
    "            if p1 is not None:\n",
    "                good_new = p1[status==1]\n",
    "                good_old = p0[status==1]\n",
    "            else:\n",
    "                # Can't do anything with this frame, so move onto next frame.\n",
    "                frame_num += 1\n",
    "                frame_path = frames_dir_path + \"/\" + clip_name + \"_frames/\" + clip_name + \"_{0:05d}\".format(frame_num) + \".jpg\"\n",
    "                continue\n",
    "                \n",
    "        # Draw optical flow tracks on top of current frame\n",
    "        if len(good_old) > 0:\n",
    "            for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "                a, b = new.ravel()\n",
    "                c, d = old.ravel()\n",
    "                # Draw displacement as line from old optical flow point location to current optical flow point location\n",
    "                mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
    "                # Draw circles for current optical flow point locations\n",
    "                frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
    "        else:\n",
    "            # If no old optical flow points for this frame, just draw circles for current optical flow points\n",
    "            for i, new in enumerate(good_new):\n",
    "                a, b = new.ravel()\n",
    "                frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
    "\n",
    "        optical_flow_img = cv2.add(frame, mask)\n",
    "        \n",
    "        # If a directory for optical flow visualization does not currently exist, make that directory\n",
    "        optical_flow_visualization_outer_dir_path = \"lk_optical_flow_visualization_err_\" + str(err_threshold) + \"_votes_\" + str(num_votes_threshold)\n",
    "        if not os.path.isdir(optical_flow_visualization_outer_dir_path):\n",
    "            ! mkdir {optical_flow_visualization_outer_dir_path}\n",
    "            \n",
    "        # If a directory for optical flow visualization for this clip does not currently exist, make that directory\n",
    "        optical_flow_visualization_dir_path = optical_flow_visualization_outer_dir_path + \"/\" + clip_name + \"_frames\"\n",
    "        if not os.path.isdir(optical_flow_visualization_dir_path):\n",
    "            ! mkdir {optical_flow_visualization_dir_path}\n",
    "        \n",
    "        # Save visualization of optical flow on current frame\n",
    "        # As the loop runs, this file will keep getting overridden; at the end, we'll just have the optical flow on the clip's last frame\n",
    "        # OpenCV imwrite expects BGR image, so convert from RGB to BGR color space before using OpenCV's imwrite function to save it\n",
    "        cv2.imwrite(optical_flow_visualization_dir_path + \"/\" + clip_name + \"_{0:05d}\".format(frame_num) + \".jpg\", cv2.cvtColor(optical_flow_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # To set up for the next iteration of the loop, update the previous frame and previous points.\n",
    "        old_gray = frame_gray.copy()\n",
    "        p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "        frame_num += 1\n",
    "        frame_path = frames_dir_path + \"/\" + clip_name + \"_frames/\" + clip_name + \"_{0:05d}\".format(frame_num) + \".jpg\"\n",
    "\n",
    "    # Return dictionary of cut detection results, where keys are frame numbers.\n",
    "    return cut_label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862c832b",
   "metadata": {},
   "source": [
    "**Run the block below to run cut detection on all the clip frames in the `frames` folder, using Lucas-Kanade optical flow.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac28c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with thresholds to find most optimal ones for cut detection using Lucas-Kanade.\n",
    "\n",
    "# A window should have err vector value above this err_threshold to contribute to a vote for a cut.\n",
    "# Error measure: L1 distance between patches around the original and a moved point, divided by number of pixels in a window.\n",
    "err_thresholds = [10, 20, 25, 30, 40, 50]\n",
    "# > 50%, 60%, 70%, 80%, 90% of the windows should have err above err_threshold for a cut to be detected btwn old_frame and frame.\n",
    "num_votes_thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# If a directory for cut label dictionaries detected using Lucas Kanade optical flow does not currently exist, make that directory\n",
    "cut_dict_outer_dir_path = \"cut_label_dicts_lk_optical_flow\"\n",
    "if not os.path.isdir(cut_dict_outer_dir_path):\n",
    "    ! mkdir {cut_dict_outer_dir_path}\n",
    "\n",
    "for err_threshold in err_thresholds:\n",
    "    for num_votes_threshold in num_votes_thresholds:\n",
    "        # Get list of all files and directories in frames directory\n",
    "        frames_dir_path = \"frames\"\n",
    "        clips_list = os.listdir(frames_dir_path)\n",
    "\n",
    "        # For each clip's frames folder...\n",
    "        for clip_folder in clips_list:\n",
    "            if clip_folder != \".DS_Store\":\n",
    "                clip_name = clip_folder.replace(\"_frames\", \"\")\n",
    "\n",
    "                # Detect cuts in the frames for current clip, using Lucas Kanade optical flow\n",
    "                cut_label_dict = detect_cuts_using_lucas_kanade_optical_flow(frames_dir_path, clip_name, err_threshold, num_votes_threshold)\n",
    "\n",
    "                # If a directory for cut label dictionaries detected using Lucas Kanade optical flow with this err_threshold and this num_votes_threshold pair does not currently exist, make that directory\n",
    "                cut_dict_dir_path = cut_dict_outer_dir_path + \"/cut_label_dicts_lk_optical_flow_err_\" + str(err_threshold) + \"_votes_\" + str(num_votes_threshold)\n",
    "                if not os.path.isdir(cut_dict_dir_path):\n",
    "                    ! mkdir {cut_dict_dir_path}\n",
    "\n",
    "                # Save (serialize) pickle of the Lucas Kanade optical flow cut detection result dictionary\n",
    "                pickled_dict_filepath = cut_dict_dir_path + \"/\" + clip_name + \"_frame_to_cut_dict\" + \".pkl\"\n",
    "                with open(pickled_dict_filepath, \"wb\") as f:\n",
    "                    pickle.dump(cut_label_dict, f)\n",
    "\n",
    "                # Test loading (deserializing) pickled data to make sure pickled file saved correctly\n",
    "                with open(pickled_dict_filepath, \"rb\") as f:\n",
    "                    pass\n",
    "                     # print(pickle.load(f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15672e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
